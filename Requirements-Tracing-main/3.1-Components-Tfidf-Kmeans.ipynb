{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0966e7",
   "metadata": {},
   "source": [
    "## User Input: Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of clusters for each component (fixed)\n",
    "num_clusters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load grouped data by component from saved pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DummyPreproccessedForTfidf.pickle\", \"rb\") as pickle_file:\n",
    "    grouped_data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: How to access a single document text:\n",
    "# grouped_data['ALPHA']['Description'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine by Subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore all groups\n",
    "groups = grouped_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### VECTORIZATION ###\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vocabulary = {}\n",
    "vocabulary_freq = {}\n",
    "group_X = {}\n",
    "for g in groups:\n",
    "    tfidf_vect = TfidfVectorizer()\n",
    "    message_list = list(grouped_data[g]['Requirement'])\n",
    "    X = tfidf_vect.fit_transform(message_list)\n",
    "    document_term_matrix = pd.DataFrame(X.toarray(), \n",
    "                                        columns=tfidf_vect.get_feature_names())\n",
    "    vocabulary[g] = tfidf_vect.vocabulary_\n",
    "    vocabulary_freq[g] = utils.count_vocab_freq(vocabulary[g], \n",
    "                                                corpus=message_list)\n",
    "    group_X[g] = X\n",
    "\n",
    "    print(g, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_X\n",
    "with open(\"VectorizationTfidf.pickle\", \"wb\") as pickle_file:\n",
    "    pickle.dump(group_X, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view vocabulary (frequency) by subgroup component \n",
    "component_group = 'ALPHA' # change to examine each component vocabulary\n",
    "vocabulary_freq[component_group]\n",
    "\n",
    "# Suggestion:  Look into acronyms used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view vocabulary from each grouped component\n",
    "for component_name in list(groups):\n",
    "    print(f'Component Name = {component_name}:')\n",
    "    print(f'{list(vocabulary_freq[component_name].items())[:30]} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163bb953",
   "metadata": {},
   "source": [
    "# Word Cloud Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184652ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word cloud of this vocabulary\n",
    "for g in list(groups):\n",
    "    print(f'{g}: Word Cloud')\n",
    "    word_cloud = WordCloud(width=3000, height=2000).generate_from_frequencies(vocabulary_freq[g])\n",
    "    word_cloud.background_color = 'white'\n",
    "    plt.figure(figsize=[15,10])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(word_cloud)\n",
    "    # plt.savefig('word_cloud.png')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for component_name in list(groups):\n",
    "#     # up to 95% of total variance\n",
    "#     pca = PCA(n_components=0.95, svd_solver='full')\n",
    "#     prin_comp = pca.fit_transform(group_X[component_name].todense())\n",
    "#     cumsum_variance = np.cumsum(pca.explained_variance_)\n",
    "    \n",
    "#     print(f'Component Name = {component_name}:')\n",
    "\n",
    "#     print(f'# of eigenvalues (principal components) needed to reach '\n",
    "#           f'{100*pca.n_components}% of explained variance: {pca.n_components_}')\n",
    "\n",
    "#     print(f'Cumulative explained variance per principal component: '\n",
    "#           f'{cumsum_variance[:4]} ... {cumsum_variance[-4:]} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means on Subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### K Means ###\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "for g in groups:\n",
    "    \n",
    "    #FIXME: Each subgroup will have a different optimal K clusters... \n",
    "    # num_clusters = 6 # defined on top cell\n",
    "    if len(grouped_data[g]) < num_clusters:\n",
    "        num_clusters = 1\n",
    "    \n",
    "    model = KMeans(n_clusters=num_clusters, \n",
    "                   init='k-means++', \n",
    "                   random_state=5).fit(group_X[g])\n",
    "    sizes = np.array(np.unique(model.labels_, \n",
    "                               return_counts=True))[1]\n",
    "    print(g, 'Cluster sizes: ', end=' ')\n",
    "    print(sizes)\n",
    "\n",
    "    grouped_data[g]['predicted'] = model.labels_\n",
    "    grouped_data[g].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ClustersTfidf.pickle\", \"wb\") as pickle_file:\n",
    "    pickle.dump(grouped_data, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
